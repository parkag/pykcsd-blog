<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">pykCSD @ GSoC</title>
<generator uri="https://github.com/mojombo/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml" />
<link rel="alternate" type="text/html" href="http://localhost:4000/" />
<updated>2014-08-11T23:50:32+02:00</updated>
<id>http://localhost:4000/</id>
<author>
  <name>Grzegorz Parka</name>
  <uri>http://localhost:4000/</uri>
  <email>grzegorz.parka@gmail.com</email>
</author>


<entry>
  <title type="html"><![CDATA[Right before the final evaluation (week 12)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week12/"/>
  <id>http://localhost:4000/articles/week12</id>
  <updated>2014-08-10T00:00:00-00:00</updated>
  <published>2014-08-10T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;We are approaching the soft deadline for GSoC2014. It’s about time to complete the documentation and close the iteration.&lt;/p&gt;

&lt;h2 id=&quot;tasks-completed-this-week&quot;&gt;Tasks completed this week:&lt;/h2&gt;

&lt;p&gt;I managed to fix some problems connected with introducing time series management in the KCSD solvers. This meant adjusting tests and any code samples where I called KCSDs.&lt;/p&gt;

&lt;h3 id=&quot;defining-use-cases-for-documentation&quot;&gt;Defining use cases for documentation&lt;/h3&gt;

&lt;p&gt;I have added some basic use cases to the documentation, so that users can start with an example.&lt;/p&gt;

&lt;p&gt;The samples may be found &lt;a href=&quot;http://pykcsd.readthedocs.org/en/latest/usecases.html&quot;&gt;here&lt;/a&gt; or built from the source.&lt;/p&gt;

&lt;h3 id=&quot;comparing-more-detailed-reconstructions-with-its-matlab-versions&quot;&gt;Comparing more detailed reconstructions with it’s matlab versions&lt;/h3&gt;
&lt;p&gt;This is done using provided datasets.&lt;/p&gt;

&lt;h5 id=&quot;d-timeseries-reconstruction&quot;&gt;1D timeseries reconstruction&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;from pylab import *
from scipy.io import loadmat
from pykCSD.pykCSD import KCSD


def timeplot_1D():
    el_pos = loadmat('datasets/test_data1')['elPos']
    pots = loadmat('datasets/test_data1')['pots']
    params = {'xmin': 0.0, 'xmax': 1.9, 'gdX': 0.01,
              'h': 1.0, 'R_init': (el_pos.T[1]-el_pos.T[0])}
    k = KCSD(el_pos.T, np.array(pots), params)
    k.estimate_pots()
    k.estimate_csd()

    fig = plt.figure()
    
    ax11 = fig.add_subplot(1,2,1)
    im1 = imshow(k.solver.estimated_pots, aspect=&quot;auto&quot;, interpolation=&quot;none&quot;)
    plt.colorbar(im1)
    ax11.set_title('Estimated pots')
    ax11.set_xlabel('time steps')
    ax11.set_ylabel('space')
    
    ax12 = fig.add_subplot(1,2,2)
    im2 = imshow(k.solver.estimated_csd, aspect=&quot;auto&quot;, interpolation=&quot;none&quot;)
    plt.colorbar(im2)
    ax12.set_title('Estimated CSD')
    ax12.set_xlabel('time steps')
    ax12.set_ylabel('space')

    show()

if __name__ == &quot;__main__&quot;:
    timeplot_1D()
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://localhost:4000/images/comparison_with_matlab_1dtimeframe_pykcsd.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/comparison_with_matlab_1dtimeframe_pykcsd.png&quot; /&gt;&lt;/a&gt;
    &lt;figcaption&gt;1D time series (no CV) - python&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://localhost:4000/images/kcsd1dtime_matlab.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/kcsd1dtime_matlab.png&quot; /&gt;&lt;/a&gt;
    &lt;figcaption&gt;1D time series (no CV) - matlab&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h5 id=&quot;kcsd2d&quot;&gt;KCSD2D&lt;/h5&gt;
&lt;figure&gt;
    &lt;a href=&quot;http://localhost:4000/images/kcsd2d_python_comp.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/kcsd2d_python_comp.png&quot; /&gt;&lt;/a&gt;
    &lt;figcaption&gt;2D single frame reconstruction(no CV) - python&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;a href=&quot;http://localhost:4000/images/kcsd2d_matlab.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/kcsd2d_matlab.png&quot; /&gt;&lt;/a&gt;
    &lt;figcaption&gt;2D single frame reconstruction (no CV) - matlab&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;package-deployment&quot;&gt;Package deployment&lt;/h3&gt;

&lt;p&gt;The built package is deployed on PIP and can be seen here.&lt;/p&gt;

&lt;p&gt;It may be installed with &lt;code&gt;sudo pip install pykCSD&lt;/code&gt;&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week12/&quot;&gt;Right before the final evaluation (week 12)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on August 10, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Completing the project (week 11)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week11/"/>
  <id>http://localhost:4000/articles/week11</id>
  <updated>2014-07-31T00:00:00-00:00</updated>
  <published>2014-07-31T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;The end of GSoC 2014 coding phase is getting closer and closer. This week I’m completing the tasks listed in the previous post.&lt;/p&gt;

&lt;h2 id=&quot;tasks-completed-this-week&quot;&gt;Tasks completed this week:&lt;/h2&gt;

&lt;h3 id=&quot;normalizing-constants-in-2d3d-basis-functions&quot;&gt;Normalizing constants in 2d/3d basis functions&lt;/h3&gt;
&lt;p&gt;It came out that 2D gaussian basis function in the previous KCSD script was not normalized. After normalization the tests which compare KCSD2D to matlab scripts are not passing. Unwillingly, I’m dropping the old KCSD2D comparison tests.&lt;/p&gt;

&lt;h3 id=&quot;creating-validation-framework&quot;&gt;Creating validation framework&lt;/h3&gt;
&lt;p&gt;This task is about creating a set of routines which help to compare 1D, 2D, 3D KCSD reconstruction against model CSD and potentials calculated using forward scheme.&lt;/p&gt;

&lt;h4 id=&quot;sample-reconstructions&quot;&gt;Sample reconstructions&lt;/h4&gt;

&lt;p&gt;1D reconstruction&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x = np.linspace(-10, 10, 100)

true_csd = 1.0 * np.exp(-(x + 2.)**2/(2 * np.pi * 0.5))
true_csd += 0.5 * np.exp(-(x - 7)**2/(2 * np.pi * 1.0))

elec_pos = np.array([-9.0, -6.9, -3.1, -0.3, 2.5, 5.7, 9.3])
params = {'xmin': -10, 'xmax': 10, 'gdX': 0.20}
indx = [5, 15, 25, 45, 51, 73, 89]

compare_with_model_1D(x, true_csd, indx, params)
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/figure_1D_model_comparison.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/figure_1D_model_comparison.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;Sample 1D comparison&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;2D reconstruction&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;xlin = np.linspace(0, 10, 101)
ylin = np.linspace(0, 10, 101)
X, Y = np.meshgrid(xlin, ylin)
true_csd = 1.0 * np.exp(-((X - 8.)**2 + (Y - 8)**2)/(2 * np.pi * 1.5))
true_csd -= 0.5 * np.exp(-((X - 1)**2 + (Y - 9)**2)/(2 * np.pi * 2.0))
true_csd += 1.5 * np.exp(-((X - 2)**2 + (Y - 2)**2)/(2 * np.pi * 2.0))
kcsd_params = {'xmin': 0, 'xmax': 10,
          'ymin': 0, 'ymax': 10,
          'gdX': 0.10, 'gdY': 0.10,
          'h': 0.5}
indx = [[5, 5], [15, 10], [25, 50], [45, 70], [51, 30],
	[73, 89], [5, 80], [90, 15], [60,90]]
compare_with_model_2D(X, Y, true_csd, indx, kcsd_params)
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/figure_2D_model_comparison.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/figure_2D_model_comparison.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;Sample 2D comparison&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;3D reconstruction is missing as I haven’t yet found a clear and simple way to display multiple 3D plots.&lt;/p&gt;

&lt;h3 id=&quot;time-series-management&quot;&gt;Time series management&lt;/h3&gt;

&lt;p&gt;The pykCSD toolbox can now estimate CSD for time recordings and calculate multiple frames.
However with many time frames and especially in the 3D case, the memory usage can go very high. This is yet to be optimized.&lt;/p&gt;

&lt;h3 id=&quot;whats-left&quot;&gt;What’s left:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Comparing images matlab/python visually (with existing datasets)&lt;/li&gt;
  &lt;li&gt;tests on bigger datasets: 100, 1000, 10k electrodes and time frames&lt;/li&gt;
  &lt;li&gt;describing workflows for documentation&lt;/li&gt;
  &lt;li&gt;package deployment&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week11/&quot;&gt;Completing the project (week 11)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on July 31, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Ensuring quality (week 10)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week10/"/>
  <id>http://localhost:4000/articles/week10</id>
  <updated>2014-07-24T00:00:00-00:00</updated>
  <published>2014-07-24T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;h3 id=&quot;code-reviewoverview&quot;&gt;Code review/overview&lt;/h3&gt;
&lt;p&gt;This week me, Daniel and one of his PhD students, Chaitanya met at Nencki Institute of Experimental Biology and made a code review.
We found few small flaws in the code, for example the new source distribution I introduced didn’t place the sources completely evenly.&lt;/p&gt;

&lt;p&gt;We also discussed the 3D laplace equation for spherical-symmetric sources, using step-case. This alternative approach is about to be added to the 3D KCSD variant.&lt;/p&gt;

&lt;h3 id=&quot;new-functionality&quot;&gt;New functionality&lt;/h3&gt;

&lt;h4 id=&quot;analytic-relation-between-lfp-and-csd&quot;&gt;Analytic relation between LFP and CSD&lt;/h4&gt;
&lt;p&gt;Daniel suggested that the package should offer a possibility to add a case in 3D kCSD, where it is possible to find an analytic solution of the relation between sources and potential.&lt;/p&gt;

&lt;p&gt;He sent me a nice pdf with the idea explained. And the conculsion is that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

V(r) = 
\left \lbrace 
\begin{array}{ll}
\displaystyle \frac{C}{4 \pi \sigma r} &amp; \textrm{for} \,\, r &gt; R \\[1em]
\displaystyle \frac{3 C}{8 \pi \sigma R^3}(R^2-r^2/3) &amp; \textrm{for} \,\,  r &lt; R  
\end{array}
\right .
 %]]&gt;&lt;/script&gt;

&lt;p&gt;where C=1 is the total current, R is source radius, r is actual position and &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; is conductance.&lt;/p&gt;

&lt;h3 id=&quot;tasks-before-the-evaluation&quot;&gt;Tasks before the evaluation&lt;/h3&gt;

&lt;p&gt;We discussed a list of tasks that should be done before the final evaluation. It consists of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;improving validation method in 2d/3d against model data&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;creating validation framework&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;recalculating normalization constants in basis functions&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;comparing images matlab/python visually (with provided data)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;time series management&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;cross validation for R and h parameters at once&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;tests on bigger datasets: 100, 1000, 10k electrodes and time frames&lt;/li&gt;
  &lt;li&gt;describing workflows&lt;/li&gt;
  &lt;li&gt;package deployment&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week10/&quot;&gt;Ensuring quality (week 10)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on July 24, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Refactoring continued (week 9)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week9/"/>
  <id>http://localhost:4000/articles/week9</id>
  <updated>2014-07-17T00:00:00-00:00</updated>
  <published>2014-07-17T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Until now I have been following the schedule pretty strictly, however it now came out that the performance of kCSD framework depends maily on Python underlying data structures, so there is not much room for algorithm/data structure optimization. Other than that, the double and triple integrals used in kCSD variants may take up to 97% of overall computation time assuming reconstruction of only 1 frame.&lt;/p&gt;

&lt;p&gt;I believe this is essential to maintaining general purpose of the library. There is another, analytical way to calculate the potential in 3D, which Daniel pointed out. This will be added as an option to use.&lt;/p&gt;

&lt;p&gt;Also this week Daniel told me to write a set of functions to compare model data and reconstructions.&lt;/p&gt;

&lt;h3 id=&quot;refactoring&quot;&gt;Refactoring&lt;/h3&gt;

&lt;p&gt;The library is already very modular, however there is still an obvious near-duplicacy of code in 1D, 2D and 3D KCSD. I intentionally made the classes as similar as possible, to make the merging easier. My idea now is to split KCSD execution into two steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;initializing model&lt;/li&gt;
  &lt;li&gt;calculating CSD and LFP with the use of the model and measured LFP data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Actually each model will stay a separate class. This is because merging all three variants into one model would create unnecesary cascades of conditional statements and will assign to much responsibility to a single class.&lt;/p&gt;

&lt;h3 id=&quot;adding-more-appropriate-tests&quot;&gt;Adding more appropriate tests&lt;/h3&gt;
&lt;p&gt;To make the process of refactoring go smoothly, I’m filling any gaps in the set of unit and functional tests I’ve prepared over the course of the last weeks.&lt;/p&gt;

&lt;h3 id=&quot;dropping-tests-that-compare-pykcsd-against-matlab-kcsd2d-version&quot;&gt;Dropping tests that compare pykCSD against Matlab kCSD2D version&lt;/h3&gt;

&lt;p&gt;During the tests of creating sources in the 2D case I found out an inconsistency. So that old (matlab based) 2d source distribution always returns &lt;script type=&quot;math/tex&quot;&gt;(\sqrt{n_{src}}+1)^2&lt;/script&gt; sources instead of &lt;script type=&quot;math/tex&quot;&gt;n_{src}&lt;/script&gt;. This will be dealt with by switching to the new source distribution based on hypervolume. Also the old approach did not manage cases, where coordinations of sources were negative. I’ve also corrected this.&lt;/p&gt;

&lt;p&gt;The package is almost ready to drop the tests of comparison against the existing Matlab scripts and switch to comparison to model only.&lt;/p&gt;

&lt;h3 id=&quot;documentation&quot;&gt;Documentation&lt;/h3&gt;
&lt;p&gt;The documentation has been improved. I decided to follow the docstring conventions from Numpy for the functions that are directly available to the user.&lt;/p&gt;

&lt;p&gt;I used sphinx-napoleon extension to Sphinx to parse the Numpy style docstrings to rst.&lt;/p&gt;

&lt;p&gt;The documentation is now hosted on readthedocs.org site: &lt;a href=&quot;http://pykcsd.readthedocs.org/en/latest/&quot;&gt;link&lt;/a&gt;&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week9/&quot;&gt;Refactoring continued (week 9)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on July 17, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Refactoring, fixing integrals (week 8)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week8/"/>
  <id>http://localhost:4000/articles/week8</id>
  <updated>2014-07-10T00:00:00-00:00</updated>
  <published>2014-07-10T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;h3 id=&quot;refactoring&quot;&gt;Refactoring&lt;/h3&gt;

&lt;p&gt;To shorten and modularize the KCSD classes better, I’m moving static functions from KCSD classes to external modules:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;cross_validation.py&lt;/li&gt;
  &lt;li&gt;basis_functions.py&lt;/li&gt;
  &lt;li&gt;source_distributions.py&lt;/li&gt;
  &lt;li&gt;potentials.py&lt;/li&gt;
  &lt;li&gt;dist_table_utils.py&lt;/li&gt;
  &lt;li&gt;plotting_utils.py&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The names are self-explanatory.&lt;/p&gt;

&lt;p&gt;The package is more granular now. It makes it much easier to stick to PEP8 rules.&lt;/p&gt;

&lt;p&gt;It’s still not fully PEP8, but over ten times closer to that! (flaw count decreased from 500 to 40 by now)&lt;/p&gt;

&lt;p&gt;There is some similar code in the KCSD classes so, it could be beneficial to merge them together, however I didn’t find a good way of doing so yet. &lt;/p&gt;

&lt;h3 id=&quot;speeding-up&quot;&gt;Speeding up&lt;/h3&gt;

&lt;h4 id=&quot;matrices&quot;&gt;Matrices&lt;/h4&gt;
&lt;p&gt;The matrix operations already look optimized. Nothing special to improve. Contrary to what I supposed in my proposal, there are no sparse matrices in kCSD in general. Some may only appear in the 1D version, which I investigated at that time. &lt;/p&gt;

&lt;p&gt;I’m leaving it as it is now. Messing with it will not bring a significant boost.&lt;/p&gt;

&lt;h4 id=&quot;integrals&quot;&gt;Integrals&lt;/h4&gt;
&lt;p&gt;There were serious problems with evaluating double and triple quads, especially when the integrands contained step function.&lt;/p&gt;

&lt;p&gt;This is because higher dimensional scipy integrals (nquad, tplquad) don’t handle discontinuities and constant functions well.
Triple quads and nquads completely refused to compute potentials with 3D step basis functions.&lt;/p&gt;

&lt;p&gt;To overcome this I decided to use other type of integration method - Monte Carlo method.&lt;/p&gt;

&lt;p&gt;I came up with Monte Carlo mthod because it handles both gaussian and step function well. Also the calculation time vs precision tradeoff can be manipulated explicitly by specifing the number of sampling points. &lt;/p&gt;

&lt;p&gt;Small comparison between Scipy tplquad and Monte Carlo integral:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;In [1]: from pykCSD import potentials as pt
In [2]: from pykCSD import basis_functions as bf
In [3]: from pylab import *
In [4]: x = np.array([0.2 * i for i in xrange(20)])
In [5]: R = 1.0
In [6]: h = 0.5
In [7]: pots_tplquad = np.array([pt.b_pot_3d_cont(xp, R, h, 1.0, bf.gauss_rescale_3D) for xp in x])
In [8]: pots_monte = np.array([pt.b_pot_3d_mc(xp, R, h, 1.0, bf.gauss_rescale_3D) for xp in x])
In [9]: plot(x, pots_tplquad)
In [10]: plot(x, pots_monte)
In [11]: show()
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/figure_monte_tpl.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/figure_monte_tpl.png&quot; /&gt;&lt;/a&gt;
&lt;figcaption&gt;Potentials calculated with scipy.integrate.tplquad and Monte Carlo method (scikit-monaco)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/figure_mc_tpl_err_pots.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/figure_mc_tpl_err_pots.png&quot; /&gt;&lt;/a&gt;
&lt;figcaption&gt;Difference between tplquad and Monte Carlo method (npts=1e5) calculated potentials&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/figure_mc_tpl_rel_err.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/figure_mc_tpl_rel_err.png&quot; /&gt;&lt;/a&gt;
&lt;figcaption&gt;Relative error between tplquad and Monte Carlo method (npts=1e5) calculated potentials&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Relative error of Monte Carlo integration method is proportional to inverse square root of the number of samples N, err = &lt;script type=&quot;math/tex&quot;&gt;O
\left(\frac{1}{\sqrt{N}}\right)&lt;/script&gt; and is not dependent on the dimensionality of the integrand.&lt;/p&gt;

&lt;p&gt;Using 100000 pts gives average relative error below 1%, which should be low enough for most of reconstructions.&lt;/p&gt;

&lt;p&gt;Speed comparison for gausian base and 20 calculations:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%time pots_tplquad = np.array([pt.b_pot_3d_cont(xp, R, h, 1.0, bf.gauss_rescale_3D) for xp in x])
CPU times: user 46.8 s, sys: 0 ns, total: 46.8 s
Wall time: 46.9 s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This takes 46.9 s for SciPy tplquad to complete, now compare to Monte Carlo with 1e5 points:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%time pots_monte = np.array([pt.b_pot_3d_mc(xp, R, h, 1.0, bf.gauss_rescale_3D) for xp in x])
CPU times: user 32 ms, sys: 172 ms, total: 204 ms
Wall time: 19.8 s
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week8/&quot;&gt;Refactoring, fixing integrals (week 8)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on July 10, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Three dimensional kCSD (week 7)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week7/"/>
  <id>http://localhost:4000/articles/week7</id>
  <updated>2014-07-06T00:00:00-00:00</updated>
  <published>2014-07-03T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;h3 id=&quot;tldr---basic-version-of-kcsd3d-works-kcsd3d-imagesplotting&quot;&gt;TL;DR: - basic version of KCSD3D works, &lt;a href=&quot;#plotting&quot;&gt;KCSD3D images&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;During the implementation of the 3D version of kCSD, there were few things to consider:&lt;/p&gt;

&lt;h3 id=&quot;distribution-of-sources-in-2d-and-3d&quot;&gt;Distribution of sources in 2D and 3D&lt;/h3&gt;
&lt;p&gt;Problem: having approx &lt;script type=&quot;math/tex&quot;&gt;n_{src}&lt;/script&gt; sources we need to distribute them evenly in 3D space.&lt;/p&gt;

&lt;p&gt;The approach proposed for two dimensions in kCSD 2D seems a bit unclear to me:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_src_params_2D(Lx, Ly, n_src):   
	coeff = [Ly, Lx - Ly, -Lx * n_src];

	rts = np.roots(coeff)
	r = [r for r in rts if type(r) is not complex and r &amp;gt; 0]

	nx = r[0]
	ny = n_src/nx

	ds = Lx/(nx-1)

	nx = np.floor(nx) + 1
	ny = np.floor(ny) + 1

	Lx_n = (nx - 1) * ds
	Ly_n = (ny - 1) * ds

	return (nx, ny, Lx_n, Ly_n, ds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which for enables to distribute sources like this:&lt;/p&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/src2d_roots.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/src2d_roots.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;old approach using roots&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;with such parameters:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(nx=6.0, ny=4.0, Lx_n=3.8359071790069814, Ly_n=2.301544307404189, ds=0.76718143580139631)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have no idea how to extend this into higher dimension.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My approach&lt;/strong&gt; is to divide the area/volume into &lt;script type=&quot;math/tex&quot;&gt;n_{src}&lt;/script&gt; parts (squares/cubes) 
and then calculate the side of each square and number of squares for each axis:&lt;/p&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/sources_3D.jpg&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/sources_3D.jpg&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;The new approach in 3D illustrated&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;pre&gt;&lt;code&gt;def get_src_params_2D_new(Lx, Ly, n_src):
	S = Lx*Ly
	S_unit = float(S)/n_src
	nx = np.ceil(Lx*S_unit**(-1./2))
	ny = np.ceil(Ly*S_unit**(-1./2))

	ds = Lx/nx

	Lx_n = (nx)*ds
	Ly_n = (ny)*ds

	return (nx, ny, Lx_n, Ly_n, ds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;for the same input as in the previous approach it gives slightly different results:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(nx=6.0, ny=4.0, Lx_n=3.2000000000000002, Ly_n=2.1333333333333333, ds=0.53333333333333333)
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/src2d_area.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/src2d_area.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;new approach using hyper-volume (length/area/volume ...)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This scales well from 2D to 3D (and beyond), since it’s based on the conception of (hyper)volume.&lt;/p&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/src3d_volume.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/src3d_volume.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;A 3D example&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;potential&quot;&gt;Potential&lt;/h3&gt;
&lt;p&gt;The potential is obviously just:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \phi(x,y,z) = \frac{1}{4 \pi \sigma} \iiint \frac{C(x',y',z') dx' dy' dz'}{\sqrt{(x-x')+(y-y')+(z-z')}}&lt;/script&gt;

&lt;p&gt;and &lt;script type=&quot;math/tex&quot;&gt;C(x,y,z)&lt;/script&gt; may be for example a 3D step function:
 &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
C(x,y,z) = \begin{cases}
										1, &amp; \text{if }x^2+y^2+z^2 &lt; R^2 \\
										0, &amp; \text{ otherwise}
									\end{cases}  %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;which can be imagined as a sphere of uniform density.&lt;/p&gt;

&lt;p&gt;or gaussian function:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C(x,y,z) = \exp \left(-\frac{(x - \mu_x)^2 + (y - \mu_y)^2 + (z - \mu_z)^2}{2\sigma ^2} \right) &lt;/script&gt;

&lt;p&gt;which can be imagined as a sphere getting denser and denser near its core. &lt;/p&gt;

&lt;p&gt;Calculated at different distances, the function may look like this:&lt;/p&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/dist_table_3d.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/dist_table_3d.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;dist table for inverse laplacian assuming gaussian base&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;memory-issues&quot;&gt;Memory issues&lt;/h3&gt;
&lt;p&gt;The main matrices used in the kCSD method may become large enough to use whole RAM, let’s investigate them:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;dist_table - O(1), typically 100x1
    &lt;ul&gt;
      &lt;li&gt;this is small and memory-safe&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;b_pot_matrix - &lt;script type=&quot;math/tex&quot;&gt;O(n_{src} \cdot n_{elec})&lt;/script&gt; 
    &lt;ul&gt;
      &lt;li&gt;grows fast with number of sources and number of electrodes&lt;/li&gt;
      &lt;li&gt;we can suppose this is safe while &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
n_{elec} &lt; 1000 %]]&gt;&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
n_{src} &lt; 1000 %]]&gt;&lt;/script&gt; (rarely violated)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;b_interp_pot_matrix - &lt;script type=&quot;math/tex&quot;&gt;O(n_{voxels} \cdot n_{src})&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;size grows rapidly with output sampling quality and number of sources &lt;/li&gt;
      &lt;li&gt;safe as long as the number of voxels (volume units) &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
n_{voxels} &lt; 1000000 %]]&gt;&lt;/script&gt; (100x100x100) which may not be met for more detailed reconstructions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;b_src_matrix - &lt;script type=&quot;math/tex&quot;&gt;O(n_{voxels} \cdot n_{src})&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;as in b_interp_pot_matrix&lt;/li&gt;
      &lt;li&gt;size could be reduced if the basis functions are axis-symmetric, but not in general.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;estimated_pots, estimated_csd - &lt;script type=&quot;math/tex&quot;&gt;O(n_{voxels} \cdot n_{timeframe})&lt;/script&gt; 
    &lt;ul&gt;
      &lt;li&gt;size grows rapidly with output sampling quality and number of time records.&lt;/li&gt;
      &lt;li&gt;with more than few timeframes, these matrices are impossible to hold in RAM and must be stored on HDD&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;plotting&quot;&gt;Plotting&lt;/h3&gt;
&lt;p&gt;There are few possibilites to visualize 3D data obtained from KCSD.&lt;/p&gt;

&lt;h4 id=&quot;matplotlib&quot;&gt;Matplotlib&lt;/h4&gt;
&lt;p&gt;Matplotlib is designed to visualize 2D data and its 3D features are very limited.
We can only visualize electrode positions in 3D as a cloud of points. Potentials and CSD can be presented as slices through chosen axes.&lt;/p&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/kcsd3d_mpl.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/kcsd3d_mpl.png&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;mayavi&quot;&gt;Mayavi&lt;/h4&gt;
&lt;p&gt;Using mayavi, there are more possibilities:&lt;/p&gt;

&lt;p&gt;Plane cuts:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pots = k.estimated_pots
mlab.pipeline.image_plane_widget(mlab.pipeline.scalar_field(pots),
				plane_orientation='x_axes',
				slice_index=10,
				)
mlab.pipeline.image_plane_widget(mlab.pipeline.scalar_field(pots),
				plane_orientation='y_axes',
				slice_index=10,
				)
mlab.outline()
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/kcsd3d_1.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/kcsd3d_1.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;Looks fine, the planes can be adjusted interactively.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Volumetric plot:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mlab.pipeline.volume(mlab.pipeline.scalar_field(pots))
mlab.outline()
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/volumetric1.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/volumetric1.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;May be a bit unclear with all the data displayed.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;pre&gt;&lt;code&gt;mlab.pipeline.volume(mlab.pipeline.scalar_field(pots), 
			vmin=pots.min()+0.2*pots.ptp(), 
			vmax=pots.max()-0.2*pots.ptp())
mlab.outline()
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/volumetric2.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/volumetric2.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;It may be convenient to display only lower 20 and upper 20 percentiles of the data&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Combined iso-surface and plane cut&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;s_pots = mlab.pipeline.scalar_field(pots)
mlab.pipeline.iso_surface(s_pots, contours=[pots.min()+0.1*pots.ptp(), ], opacity=0.1)
mlab.pipeline.iso_surface(s_pots, contours=[pots.max()-0.1*pots.ptp(), ],)
mlab.pipeline.image_plane_widget(s_pots,
				plane_orientation='z_axes',
				slice_index=10,
				)
mlab.outline()
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/combined.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/combined.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;Combined approach&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;PS. to avoid freezes in mayavi.mlab 3D visualizer a proper gui should be used:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%gui wx
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;external-plotter---paraview&quot;&gt;External plotter - Paraview&lt;/h4&gt;
&lt;p&gt;Paraview is a library built for data analysis and visualization. It’s optimized to work with big datasets. Worth a try!&lt;/p&gt;

&lt;h3 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h3&gt;
&lt;p&gt;Now that the basic versions of KCSD in 1D, 2D, 3D are implemented, there are few things to manage:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Refactoring
    &lt;ul&gt;
      &lt;li&gt;improving readability&lt;/li&gt;
      &lt;li&gt;reducing code redundancy - each KCSD class is based on the same template. It would be nice to merge them, but only if the code stays readable. &lt;/li&gt;
      &lt;li&gt;static functions will be moved to appropriate modules (say: source_templates, source_management, model_potential, cross_validation)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;managing big datasets - some matrices should be read from HDD dynamically and not kept in RAM all the time
    &lt;ul&gt;
      &lt;li&gt;check np.memmap and hdf5 data format&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;investigate how much speedup can be achieved
    &lt;ul&gt;
      &lt;li&gt;especially: fix the n-dimensional integrals (numpy warns they don’t converge fast enough), especially if we use step basis.&lt;/li&gt;
      &lt;li&gt;investigate if Monte Carlo integration would be useful for triple integrals&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;more tests, better documentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After managing this, the package will be ready to be deployed.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week7/&quot;&gt;Three dimensional kCSD (week 7)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on July 03, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Handling delays, midterm evaluation, next step (week 6)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week6/"/>
  <id>http://localhost:4000/articles/week6</id>
  <updated>2014-06-27T00:00:00-00:00</updated>
  <published>2014-06-26T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;I had to pass my exams as quickly as possible and so did I.
After two days of my examination period and I am already done!&lt;/p&gt;

&lt;h3 id=&quot;kcsd2d&quot;&gt;KCSD2D&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;The two dimensional variant of KCSD works.
A sample reconstruction looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;In [1]: from pykCSD.pykCSD import KCSD
In [2]: import numpy as np
In [3]: elec_pos = np.array([[0, 0], [0, 1], [1,0], [1,1], [0.5,0.5]])
In [4]: pots = np.array([0,0,0,0,1])
In [5]: k = KCSD(elec_pos, pots, params={'x_min': -2, 'x_max': 2, 'y_min':-2, 'y_max':2})
In [6]: k.estimate_pots()
In [7]: k.estimate_csd()
In [8]: k.plot_all()
&lt;/code&gt;&lt;/pre&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/kcsd2d_reconstruction.png&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/kcsd2d_reconstruction.png&quot; /&gt;&lt;/a&gt;
	&lt;figcaption&gt;Sample reconstruction&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The current limitations are similar as in the KCSD1D case (no time recordings reconstruction and whole data in RAM) which will be worked upon.&lt;/p&gt;

&lt;h3 id=&quot;midterm-evaluation&quot;&gt;Midterm evaluation&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;The first part of Google Summer of Code passed so rapidly I barely noticed the midterm evaluation! Passed! :)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hi Grzegorz Parka,&lt;/p&gt;

  &lt;p&gt;We have processed the evaluation for your project named Object Oriented Python Kernel Current Source Density toolbox with International Neuroinformatics Coordinating Facility.&lt;/p&gt;

  &lt;p&gt;Congratulations, from our data it seems that you have successfully passed the Google Summer of Code 2014 - Midterm Evaluation. Please contact your mentor to discuss the results of your evaluation and to plan your goals and development plan for the rest of the program&lt;/p&gt;

  &lt;p&gt;Greetings,
The Google Open Source Programs Team&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Actually I’m on the right track following the schedule from my proposal.&lt;/p&gt;

&lt;h3 id=&quot;bonus-from-google-and-acm&quot;&gt;Bonus from Google and ACM&lt;/h3&gt;
&lt;p&gt;There is an additional surprise for us, GSoC students :)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hi GSoC 2014 students,&lt;/p&gt;

  &lt;p&gt;The ACM has offered to give you all ACM Student Memberships with
Digital Library access (which is the benefits of student membership
plus access to the ACM Digital Library, an electronic subscription to
both CACM and XRDS) this year. We will be issuing these memberships to
you starting 14 July. You will receive an email directly from the ACM
confirming your membership then.&lt;/p&gt;

  &lt;p&gt;(…)&lt;/p&gt;

  &lt;p&gt;Thanks,
Carol&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is like one of the most useful gifts I’ve been given in years! I love reading scientific articles! :D&lt;/p&gt;

&lt;h3 id=&quot;next-step&quot;&gt;Next step&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;Now when I have the 1D and 2D cases working, it’s time to implement the 3D case. This time no dimension is missing so the relation between sources and potentials becomes simply:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \phi(x,y,z) = \frac{1}{4 \pi \sigma}\iiint \frac{dx' dy' dz' C(x',y',z')}{\sqrt{(x-x')^2+(y-y')^2+(z-z')^2}} &lt;/script&gt;

&lt;p&gt;The size of basis matrices may now become an issue (the basis source matrix expected size is now in 100’s MBs). We will find out soon!&lt;/p&gt;

&lt;p&gt;Also expect some 3D plots soon!&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week6/&quot;&gt;Handling delays, midterm evaluation, next step (week 6)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on June 26, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Two dimensional kCSD (week 5)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week5/"/>
  <id>http://localhost:4000/articles/week5</id>
  <updated>2014-06-19T00:00:00-00:00</updated>
  <published>2014-06-19T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;During this week I am still working on KCSD2D and passing exams at the Uni.&lt;/p&gt;

&lt;p&gt;There was a funny problem, which took me a while to find, different type casting in Matlab and Python:&lt;/p&gt;

&lt;p&gt;Python:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;np.uint16(0.1)
&amp;gt;&amp;gt; 0
np.uint16(0.6)
&amp;gt;&amp;gt; 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Matlab:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;uint16(0.1)
&amp;gt;&amp;gt; 0
uint16(0.6)
&amp;gt;&amp;gt; 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This means that &lt;code&gt;uint16(x)&lt;/code&gt; from Matlab may be translated to Python as &lt;code&gt;np.uint16(round(x))&lt;/code&gt; obviously. It took me a while to find it out though.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week5/&quot;&gt;Two dimensional kCSD (week 5)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on June 19, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Two dimensional kCSD (week 4)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week4/"/>
  <id>http://localhost:4000/articles/week4</id>
  <updated>2014-06-12T00:00:00-00:00</updated>
  <published>2014-06-12T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;kcsd-1d&quot;&gt;KCSD 1D&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;The basic version of 1D KCSD is in repo and works, however it still can be improved significantly. The current limitations are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the results are not compatible enough with the previous version (I will aim for difference &amp;lt;.1%)&lt;/li&gt;
  &lt;li&gt;lack of support for time dependent recordings&lt;/li&gt;
  &lt;li&gt;lack of automated choice of optimal basis function width&lt;/li&gt;
  &lt;li&gt;currently whole data is kept in RAM (this might be insufficient for very large datasets)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I will be eliminating the limitations and adding features gradually as I go along. 
This will be connected with unifying the interfaces of 1D, 2D, 3D KCSD.&lt;/p&gt;

&lt;h2 id=&quot;kcsd-2d&quot;&gt;KCSD 2D&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;The next two weeks are pretty intensive for me as I must to finish my university assignments and pass the examination period.
However I will do my best and put as much time as possible into the project.&lt;/p&gt;

&lt;p&gt;The next two or three weeks will be spent on developing two dimensional version of the KCSD method (KCSD2D). It assumes that data is collected with planar electrodes.&lt;/p&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/pykcsd2D_plane.jpg&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/pykcsd2D_plane.jpg&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;This time we need to model our potentials in one missing dimension and reconstruct sources in two dimensions.
The relation between potentials and CSD in two dimensional case is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \phi(x,y) = \frac{1}{2\pi\sigma} \int dx' \int dy' \text{arsinh}\left( \frac{2h}{\sqrt{(x-x')^2 + (y-y')^2}} \right) C(x',y')&lt;/script&gt;

&lt;p&gt;assuming symmetry &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
H(z) = \begin{cases}
										1, &amp; \text{if } -h \leq z \leq h\\
										0, &amp; \text{ otherwise}
									\end{cases}  %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;There is a bit more juggling about distributing the sources properly.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week4/&quot;&gt;Two dimensional kCSD (week 4)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on June 12, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[One dimensional kCSD (week 3)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week3/"/>
  <id>http://localhost:4000/articles/week3</id>
  <updated>2014-06-05T00:00:00-00:00</updated>
  <published>2014-06-05T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;During this week I am finishing the kCSD implementation that works with data from 1D measurements, moving the code to the main repository and writing tests.&lt;/p&gt;

&lt;p&gt;Some thoughts from the last days:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;I thought there were some problems with cross validation in 1D pykCSD because it was returning high regularization parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; for model data, where it should return very low values. My mentor, Daniel, suggested that my model sources or potentials could be wrong. And yeah&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, it turned out that I was indeed calculating the initial potentials incorrectly.
The correct relation in 1D is:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt; \phi(z) = \frac{1}{2 \sigma} \int  \sqrt{(z-z_0)^2 + R^2 } - \lvert z-z_0 \rvert)C(z) dz&lt;/script&gt;

    &lt;p&gt;This is done assuming cylindrical symmetry &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
H(x,y) = \begin{cases}
                                     1, &amp; \text{if } x^2 + y^2 \leq h^2\\
                                     0, &amp; \text{ otherwise}
                                 \end{cases} 
  %]]&gt;&lt;/script&gt; &lt;/p&gt;

    &lt;p&gt;and &lt;script type=&quot;math/tex&quot;&gt;C(z)&lt;/script&gt; is the measured CSD&lt;/p&gt;

    &lt;figure&gt;
     &lt;a href=&quot;http://localhost:4000/images/pykcsd1D_cylinder.jpg&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/pykcsd1D_cylinder.jpg&quot; /&gt;&lt;/a&gt;
 &lt;/figure&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What is the added value so far? &lt;/p&gt;

    &lt;p&gt;More generalized scheme for cross validation. The existing script used something like randomized Leave One Out cross validation (which, to confuse me, was commented and called as a KFold cross validation). My &lt;a href=&quot;http://nbviewer.ipython.org/github/parkag/notebooks/blob/master/pykCSD/pykCSD%20refactored.ipynb&quot;&gt;current version&lt;/a&gt; is able to accept any combination of indices (LeaveOneOut, KFold, ShuffleSplit and so on) which can be obtained with the use of index generators from the  Scikit-learn cross_validation module.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Already looking more deeply into 2D kCSD code, it turns out that 1D and 2D implementations have more in common than I originally thought. If I recognized it properly, only the basis function management changes among the different method dimensionalities. Everything else is based on kernel operations which look all the same both in 1D and 2D.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;I think everything Daniel told me so far turned out to be true and helpful :P &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week3/&quot;&gt;One dimensional kCSD (week 3)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on June 05, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[One dimensional kCSD (week 2)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week2/"/>
  <id>http://localhost:4000/articles/week2</id>
  <updated>2014-05-29T00:00:00-00:00</updated>
  <published>2014-05-29T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;During this week I am working on the kCSD implementation that works with data from measurements made by electrodes organized in lines.&lt;/p&gt;

&lt;p&gt;Meanwhile I would like to tell what I learnt about regularization and cross validation in the context of regression.
This is summed up in &lt;a href=&quot;http://nbviewer.ipython.org/github/parkag/notebooks/blob/master/pykCSD/RLS%20and%20cross%20validation.ipynb&quot;&gt;this notebook&lt;/a&gt;. This is a nice introduction to machine learning :)&lt;/p&gt;

&lt;p&gt;I am still writing the pykCSD in IPython notebook and my current progress can be tracked &lt;a href=&quot;http://nbviewer.ipython.org/github/parkag/notebooks/blob/master/pykCSD/pykCSD%20refactored.ipynb&quot;&gt;here&lt;/a&gt;. This version will soon become obsolete as it will be reorganized and moved to the proper python source files in INCF/pykCSD repo.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week2/&quot;&gt;One dimensional kCSD (week 2)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on May 29, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Coding period starts (week 1)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week1/"/>
  <id>http://localhost:4000/articles/week1</id>
  <updated>2014-05-22T00:00:00-00:00</updated>
  <published>2014-05-22T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;We are now in the begining of the coding period. I will use this week to create the common interface for accessing the kCSD solvers for different dimensionality. It is a kind of stub that will be useful later and will help to create a clean and consistent interface.&lt;/p&gt;

&lt;p&gt;This doesn’t take whole week and leaves some time for more challenging activities, such as exploring the kCSD method deeper.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week1/&quot;&gt;Coding period starts (week 1)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on May 22, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Confusing definitions]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/confusion/"/>
  <id>http://localhost:4000/articles/confusion</id>
  <updated>2014-05-21T00:00:00-00:00</updated>
  <published>2014-05-20T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;&lt;strong&gt;Definitions&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#currentchargecurrent-source-density&quot;&gt;(Current/Charge/Current Source) Density&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#kernel-density&quot;&gt;Kernel Density&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The pykCSD project requires good knowledge of linear algebra, calculus, statistics and (bio)electromagnetism. Trying to fully understand the Kernel Current Source Density method I found few misleading definitions more or less connected with the topic. I would like to keep them here for the future reference.&lt;/p&gt;

&lt;h1 id=&quot;currentchargecurrent-source-density&quot;&gt;(Current/Charge/Current Source) Density&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Current Density&lt;/strong&gt; &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;script type=&quot;math/tex&quot;&gt;\vec{J}&lt;/script&gt; is the electric current &lt;script type=&quot;math/tex&quot;&gt;\Delta I&lt;/script&gt; (moving charge) per unit area S &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vec{J} = \lim_{S \rightarrow 0} \frac{\Delta I(S) \widehat{a}_{max}}{S} \left[ \frac{A}{m^2}\right], \text{ where } \Delta I = \lim_{\Delta t \rightarrow 0}\frac{\Delta Q}{\Delta t}&lt;/script&gt;

&lt;p&gt;which is a vector.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Charge Density&lt;/strong&gt; is electric charge per unit volume (or area or line)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \rho_q = \lim_{V \rightarrow 0} \frac{Q}{V} \left[ \frac{C}{m^3}\right]&lt;/script&gt;

&lt;p&gt;which is a scalar.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Current Source Density&lt;/strong&gt; &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; has the meaning of volume density of current entering or leaving the medium at some point in space.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C(r,t) = \sum_{n=1}^N I_n(t)\delta ^3(r-r_n) \left[\frac{A}{m^3} \right]&lt;/script&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \phi(r, t) = \frac{1}{4 \pi \sigma} \iiint \frac{ C(r', t) }{  \lvert r-r' \rvert } d^3 r' &lt;/script&gt;

&lt;h1 id=&quot;kernel-density&quot;&gt;Kernel Density&lt;/h1&gt;
&lt;p&gt;Despite its name, this is not directly related to the kCSD method.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;http://www.mathworks.com/help/stats/kernel-distribution.html&lt;/li&gt;
  &lt;li&gt;http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV0405/MISHRA/kde.html&lt;/li&gt;
  &lt;li&gt;http://scikit-learn.org/stable/modules/density.html&lt;/li&gt;
  &lt;li&gt;http://en.wikipedia.org/wiki/Kernel_density_estimation&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Current_density&quot;&gt;Current density at wikipedia&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.csc.kth.se/~helinden/PettersenLindenDaleEinevoll-BookChapter-revised.pdf&quot;&gt;Current source density&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/confusion/&quot;&gt;Confusing definitions&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on May 20, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Community Bonding Period and preparation (Week -1)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week-minus-1/"/>
  <id>http://localhost:4000/articles/week-minus-1</id>
  <updated>2014-05-15T00:00:00-00:00</updated>
  <published>2014-05-15T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;setting-up-the-environment&quot;&gt;Setting up the environment&lt;/h2&gt;

&lt;p&gt;During this week I’ve set the &lt;a href=&quot;https://github.com/INCF/pykCSD&quot;&gt;project repository&lt;/a&gt;.
I followed these posts &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; to start the project using current best practices. This includes reusing audreyr’s cookiecutter and &lt;em&gt;pypackage&lt;/em&gt; template.&lt;/p&gt;

&lt;p&gt;The first impression is that the template contains a bit too many text and config files (running tests, generating documentation, deploying to PyPI), but I believe that getting familliar with them will pay off in the next stages of the project.&lt;/p&gt;

&lt;p&gt;The template includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Makefile with commands for building, cleaning, testing, deploying&lt;/li&gt;
  &lt;li&gt;Travis-CI automatic testing configuration file&lt;/li&gt;
  &lt;li&gt;Makefile for building Sphinx-powered documentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Which is basically all that’s required to automate project workflow.&lt;/p&gt;

&lt;h2 id=&quot;other-than-that&quot;&gt;Other than that&lt;/h2&gt;

&lt;p&gt;Meanwhile I am also learning about &lt;a href=&quot;http://scikit-learn.org/stable/modules/cross_validation.html&quot;&gt;cross-validation&lt;/a&gt; and the Scikit-learn package. I will try to use the existing cross-validation from Scikit-learn to find the regularization parameter for smoothing the data in kCSD. This is useful for determining and reducing the noise from the potential measurements.&lt;/p&gt;

&lt;p&gt;My idea is to create hacky and experimental versions as scripts in IPython notebook and then gradually refactor and move new features to the project on the INCF repo.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.jeffknupp.com/blog/2013/08/16/open-sourcing-a-python-project-the-right-way/&quot;&gt;Jeff Knupp: Open Sourcing a Python Project - the right way&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://pydanny.com/cookie-project-templates-made-easy.html&quot;&gt;Daniel Greenfield: Cookie project templates made easy&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week-minus-1/&quot;&gt;Community Bonding Period and preparation (Week -1)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on May 15, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Community Bonding Period (Week -2)]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/week-minus-2/"/>
  <id>http://localhost:4000/articles/week-minus-2</id>
  <updated>2014-05-07T00:00:00-00:00</updated>
  <published>2014-05-08T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;early-coding&quot;&gt;Early coding&lt;/h2&gt;

&lt;p&gt;During this week I’ve done some early hacking and made a brutal Python port of the existing one-dimensional kCSD variant. The purpose of this port was to familliarize myself with the existing program flow and visualize some partial matrices.&lt;/p&gt;

&lt;p&gt;Surprisingly, making kCSD work in such fashion required only minor changes to the original Matlab code.&lt;/p&gt;

&lt;p&gt;An IPython Notebook may be viewed &lt;a href=&quot;http://nbviewer.ipython.org/github/parkag/notebooks/blob/master/pykCSD/pykCSD.ipynb&quot;&gt;here&lt;/a&gt; (sometimes you need to refresh the page few times before it finally renders the notebook).&lt;/p&gt;

&lt;p&gt;Yesterday I met with my Mentor, Daniel Wójcik (living in Warsaw I have the privilege to meet with him in person). He suggested that the kCSD framework may be split into two independent parts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;statistical part&lt;/li&gt;
  &lt;li&gt;basis function managing part&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is possible that the statistical part will be shared among all the dimensionalities later on. &lt;/p&gt;

&lt;p&gt;The basis function management part will be different for each dimensionality. This is because in lower dimensionality (d &amp;lt; 3) we need to assume a specific distribution of sources for the missing dimensions.&lt;/p&gt;

&lt;h2 id=&quot;community-bonding&quot;&gt;Community Bonding&lt;/h2&gt;

&lt;p&gt;After discussing the kCSD details, we also spoke about the current projects in both Nencki Institute and INCF, such as &lt;a href=&quot;http://www.3dbar.org&quot;&gt;digital Brain Atlasses&lt;/a&gt; (3dbar), &lt;a href=&quot;http://www.openworm.org/&quot;&gt;OpenWorm&lt;/a&gt; and few smaller ones.&lt;/p&gt;

&lt;p&gt;By a coincidence, one of the creators of 3dbar, who is also one of INCF mentors at GSoC 2014, Piotr Majka was going to practise before his PhD thesis defense shortly afterwards. So I became a part of his audience.&lt;/p&gt;

&lt;figure&gt;
	&lt;a href=&quot;http://localhost:4000/images/pm_defense_prep.jpg&quot;&gt;&lt;img src=&quot;http://localhost:4000/images/pm_defense_prep.jpg&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;Piotr told us about his successful procedure of integration of brain imaging data obtained from immunohistochemical stains, blockface images and through MRI to produce high-quality and consistent digital brain atlasses. He used the procedure to create a first complete &lt;a href=&quot;http://atlasing.incf.org/w/images/2/25/Majka_poster_neuroinformatics_2012.jpg&quot;&gt;reconstruction of an opossum’s brain&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Seeing my enthusiasm, he also invited me to his public PhD thesis defense on the following Friday.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/week-minus-2/&quot;&gt;Community Bonding Period (Week -2)&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on May 08, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Google Summer of Code pykCSD proposal]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/articles/proposal/"/>
  <id>http://localhost:4000/articles/proposal</id>
  <updated>2014-05-03T00:00:00-00:00</updated>
  <published>2014-05-03T00:00:00+02:00</published>
  
  <author>
    <name>Grzegorz Parka</name>
    <uri>http://localhost:4000</uri>
    <email>grzegorz.parka@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;I am very happy to announce that my proposal&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; has been accepted by the members of INCF and I will work on Python Object Oriented Kernel Current Source Density Toolbox project during this summer.&lt;/p&gt;

&lt;p&gt;The goal of the project is to implement the recently developed Kernel Current Source Density method using an open and scientist-friendly stack – Python, Numpy and Scipy. &lt;/p&gt;

&lt;p&gt;This is going to be a great summer!&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;http://localhost:4000/images/gsoc_horizontal.jpg&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.google-melange.com/gsoc/proposal/public/google/gsoc2014/grzegorz_parka/5629499534213120&quot;&gt;Link to the proposal and the timeline&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/articles/proposal/&quot;&gt;Google Summer of Code pykCSD proposal&lt;/a&gt; was originally published by Grzegorz Parka at &lt;a href=&quot;http://localhost:4000&quot;&gt;pykCSD @ GSoC&lt;/a&gt; on May 03, 2014.&lt;/p&gt;</content>
</entry>

</feed>
